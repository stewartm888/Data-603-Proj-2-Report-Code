{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Reading the MNIST data set\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 0., 0., ..., 0., 0., 0.],\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [9., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [9., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "train_data = np.loadtxt(\"mnist_train.csv\", \n",
    "                        delimiter=\",\")\n",
    "test_data = np.loadtxt(\"mnist_test.csv\", \n",
    "                       delimiter=\",\") \n",
    "test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data==255]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images of the MNIST dataset are greyscale and the pixels range between 0 and 255 including both bounding values. We will map these values into an interval from [0.01, 1] by multiplying each pixel by 0.99 / 255 and adding 0.01 to the result. This way, we avoid 0 values as inputs, which are capable of preventing weight updates, as we we seen in the introductory chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac = 0.99 / 255\n",
    "train_imgs = np.asfarray(train_data[:, 1:]) * fac + 0.01\n",
    "test_imgs = np.asfarray(test_data[:, 1:]) * fac + 0.01\n",
    "\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_labels = np.asfarray(test_data[:, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the labels in our calculations in a one-hot representation. We have 10 digits from 0 to 9, i.e. lr = np.arange(10).\n",
    "\n",
    "Turning a label into one-hot representation can be achieved with the command: (lr==label).astype(np.int)\n",
    "\n",
    "We demonstrate this in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0  in one-hot representation:  [1 0 0 0 0 0 0 0 0 0]\n",
      "label:  1  in one-hot representation:  [0 1 0 0 0 0 0 0 0 0]\n",
      "label:  2  in one-hot representation:  [0 0 1 0 0 0 0 0 0 0]\n",
      "label:  3  in one-hot representation:  [0 0 0 1 0 0 0 0 0 0]\n",
      "label:  4  in one-hot representation:  [0 0 0 0 1 0 0 0 0 0]\n",
      "label:  5  in one-hot representation:  [0 0 0 0 0 1 0 0 0 0]\n",
      "label:  6  in one-hot representation:  [0 0 0 0 0 0 1 0 0 0]\n",
      "label:  7  in one-hot representation:  [0 0 0 0 0 0 0 1 0 0]\n",
      "label:  8  in one-hot representation:  [0 0 0 0 0 0 0 0 1 0]\n",
      "label:  9  in one-hot representation:  [0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lr = np.arange(10)\n",
    "\n",
    "for label in range(10):\n",
    "    one_hot = (lr==label).astype(np.int)\n",
    "    print(\"label: \", label, \" in one-hot representation: \", one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We are ready now to turn our labelled images into one-hot representations. \n",
    "#Instead of zeroes and one, we create 0.01 and 0.99, which will be better for our calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = np.arange(no_of_different_labels)\n",
    "\n",
    "# transform labels into one hot representation\n",
    "train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
    "test_labels_one_hot = (lr==test_labels).astype(np.float)\n",
    "\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Before we start using the MNIST data sets with our neural network, we will have a look at some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    img = train_imgs[i].reshape((28,28))\n",
    "    plt.imshow(img, cmap=\"Greys\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Dumping the Data for Faster Reload\n",
    "---\n",
    "You may have noticed that it is quite slow to read in the data from the csv files.\n",
    "\n",
    "We will save the data in binary format with the dump function from the pickle module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pickled_mnist.pkl\", \"bw\") as fh:\n",
    "    data = (train_imgs, \n",
    "            test_imgs, \n",
    "            train_labels,\n",
    "            test_labels,\n",
    "            train_labels_one_hot,\n",
    "            test_labels_one_hot)\n",
    "    pickle.dump(data, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able now to read in the data by using pickle.load. This is a lot faster than using loadtxt on the csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pickled_mnist.pkl\", \"br\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "\n",
    "train_imgs = data[0]\n",
    "test_imgs = data[1]\n",
    "train_labels = data[2]\n",
    "test_labels = data[3]\n",
    "train_labels_one_hot = data[4]\n",
    "test_labels_one_hot = data[5]\n",
    "\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Classifying the Data\n",
    "---\n",
    "We will use the following neuronal network class for our first classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "activation_function = sigmoid\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd, \n",
    "                     (upp - mean) / sd, \n",
    "                     loc=mean, \n",
    "                     scale=sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate):\n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes\n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "        self.learning_rate = learning_rate \n",
    "        self.create_weight_matrices()\n",
    "        \n",
    "    def create_weight_matrices(self):\n",
    "        \"\"\" \n",
    "        A method to initialize the weight \n",
    "        matrices of the neural network\n",
    "        \"\"\"\n",
    "        rad = 1 / np.sqrt(self.no_of_in_nodes)\n",
    "        X = truncated_normal(mean=0, \n",
    "                             sd=1, \n",
    "                             low=-rad, \n",
    "                             upp=rad)\n",
    "        self.wih = X.rvs((self.no_of_hidden_nodes, \n",
    "                                       self.no_of_in_nodes))\n",
    "        rad = 1 / np.sqrt(self.no_of_hidden_nodes)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        self.who = X.rvs((self.no_of_out_nodes, \n",
    "                                         self.no_of_hidden_nodes))\n",
    "        \n",
    "    \n",
    "    def train(self, input_vector, target_vector):\n",
    "        \"\"\"\n",
    "        input_vector and target_vector can \n",
    "        be tuple, list or ndarray\n",
    "        \"\"\"\n",
    "        \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        \n",
    "        output_vector1 = np.dot(self.wih, \n",
    "                                input_vector)\n",
    "        output_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        output_vector2 = np.dot(self.who, \n",
    "                                output_hidden)\n",
    "        output_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_network\n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_network \\\n",
    "              * (1.0 - output_network)     \n",
    "        tmp = self.learning_rate  * np.dot(tmp, \n",
    "                                           output_hidden.T)\n",
    "        self.who += tmp\n",
    "\n",
    "\n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.who.T, \n",
    "                               output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_hidden * \\\n",
    "              (1.0 - output_hidden)\n",
    "        self.wih += self.learning_rate \\\n",
    "                          * np.dot(tmp, input_vector.T)\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        output_vector = np.dot(self.wih, \n",
    "                               input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        output_vector = np.dot(self.who, \n",
    "                               output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "    \n",
    "        return output_vector\n",
    "            \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        cm = np.zeros((10, 10), int)\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            cm[res_max, int(target)] += 1\n",
    "        return cm    \n",
    "\n",
    "    def precision(self, label, confusion_matrix):\n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        \n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
    "                    no_of_out_nodes = 10, \n",
    "                    no_of_hidden_nodes = 100,\n",
    "                    learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_imgs)):\n",
    "    ANN.train(train_imgs[i], train_labels_one_hot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.] 7 0.9946084113480487\n",
      "[2.] 2 0.8316255786585525\n",
      "[1.] 1 0.9937871450791433\n",
      "[0.] 0 0.9727236287406174\n",
      "[4.] 4 0.9743522654322594\n",
      "[1.] 1 0.9891660027740605\n",
      "[4.] 4 0.9804594873103954\n",
      "[9.] 9 0.9164984153371314\n",
      "[5.] 6 0.2686481620832586\n",
      "[9.] 9 0.9683773273138732\n",
      "[0.] 0 0.9680800692465874\n",
      "[6.] 6 0.8647948153130123\n",
      "[9.] 9 0.9915541070737977\n",
      "[0.] 0 0.9937366398695114\n",
      "[1.] 1 0.9927222384475506\n",
      "[5.] 5 0.9172712877146926\n",
      "[9.] 9 0.9924501871191468\n",
      "[7.] 7 0.9879949835165412\n",
      "[3.] 3 0.836444016623964\n",
      "[4.] 4 0.9798692568967728\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    res = ANN.run(test_imgs[i])\n",
    "    print(test_labels[i], np.argmax(res), np.max(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train:  0.9491\n",
      "accuracy: test 0.9475\n",
      "[[5816    1   56   13    8   44   38    9   22   33]\n",
      " [   0 6631   42   22   15   35   16   50   98   14]\n",
      " [   5   24 5522   63   12   18    5   49   20    4]\n",
      " [   1   31   94 5800    1  148    2   23  127   78]\n",
      " [  15   12   63   10 5512   32   10   37   31   93]\n",
      " [   1    4    2   46    1 4948   29    2   14    6]\n",
      " [  38    5   57   27   52   75 5781    5   38    2]\n",
      " [   1    5   41   53    8   11    0 5878    3   34]\n",
      " [  40   14   67   46   15   62   37   12 5406   33]\n",
      " [   6   15   14   51  218   48    0  200   92 5652]]\n",
      "digit:  0 precision:  0.9819348303224718 recall:  0.9629139072847682\n",
      "digit:  1 precision:  0.9835360427172946 recall:  0.9578217535750397\n",
      "digit:  2 precision:  0.9268210808996308 recall:  0.9650471862984971\n",
      "digit:  3 precision:  0.9460120698091665 recall:  0.9199048374306106\n",
      "digit:  4 precision:  0.9435124957206437 recall:  0.9478933791917454\n",
      "digit:  5 precision:  0.912746725696366 recall:  0.9792202651889966\n",
      "digit:  6 precision:  0.9768502872592092 recall:  0.9508223684210526\n",
      "digit:  7 precision:  0.9382282521947326 recall:  0.9741465031488233\n",
      "digit:  8 precision:  0.9239446248504529 recall:  0.9431263084438242\n",
      "digit:  9 precision:  0.9500756429652042 recall:  0.897712833545108\n"
     ]
    }
   ],
   "source": [
    "corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\n",
    "print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
    "corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\n",
    "print(\"accuracy: test\", corrects / ( corrects + wrongs))\n",
    "\n",
    "cm = ANN.confusion_matrix(train_imgs, train_labels)\n",
    "print(cm)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"digit: \", i, \"precision: \", ANN.precision(i, cm), \"recall: \", ANN.recall(i, cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Multiple Runs\n",
    "---\n",
    "#We can repeat the training multiple times. Each run is called an \"epoch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "accuracy train:  0.9488\n",
      "accuracy: test 0.9487\n",
      "epoch:  1\n",
      "accuracy train:  0.9623666666666667\n",
      "accuracy: test 0.9565\n",
      "epoch:  2\n",
      "accuracy train:  0.9706166666666667\n",
      "accuracy: test 0.9621\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "NN = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
    "                   no_of_out_nodes = 10, \n",
    "                   no_of_hidden_nodes = 100,\n",
    "                   learning_rate = 0.1)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    print(\"epoch: \", epoch)\n",
    "    for i in range(len(train_imgs)):\n",
    "        NN.train(train_imgs[i], \n",
    "                 train_labels_one_hot[i])\n",
    "  \n",
    "    corrects, wrongs = NN.evaluate(train_imgs, train_labels)\n",
    "    print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
    "    corrects, wrongs = NN.evaluate(test_imgs, test_labels)\n",
    "    print(\"accuracy: test\", corrects / ( corrects + wrongs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We want to do the multiple training of the training set inside of our network. \n",
    "#To this purpose we rewrite the method train and add a method train_single. train_single is more or less what we called 'train' before. \n",
    "#Whereas the new 'train' method is doing the epoch counting. For testing purposes, we save the weight matrices after each epoch in\n",
    "#the list intermediate_weights. This list is returned as the output of train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "activation_function = sigmoid\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd, \n",
    "                     (upp - mean) / sd, \n",
    "                     loc=mean, \n",
    "                     scale=sd)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate):\n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes\n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "        self.learning_rate = learning_rate \n",
    "        self.create_weight_matrices()\n",
    "        \n",
    "    def create_weight_matrices(self):\n",
    "        \"\"\" A method to initialize the weight matrices of the neural network\"\"\"\n",
    "        rad = 1 / np.sqrt(self.no_of_in_nodes)\n",
    "        X = truncated_normal(mean=0, \n",
    "                             sd=1, \n",
    "                             low=-rad, \n",
    "                             upp=rad)\n",
    "        self.wih = X.rvs((self.no_of_hidden_nodes, \n",
    "                                       self.no_of_in_nodes))\n",
    "        rad = 1 / np.sqrt(self.no_of_hidden_nodes)\n",
    "        X = truncated_normal(mean=0, \n",
    "                             sd=1, \n",
    "                             low=-rad, \n",
    "                             upp=rad)\n",
    "        self.who = X.rvs((self.no_of_out_nodes, \n",
    "                                        self.no_of_hidden_nodes))\n",
    "        \n",
    "    \n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        \"\"\"\n",
    "        input_vector and target_vector can be tuple, \n",
    "        list or ndarray\n",
    "        \"\"\"\n",
    "        \n",
    "        output_vectors = []\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "\n",
    "        \n",
    "        output_vector1 = np.dot(self.wih, \n",
    "                                input_vector)\n",
    "        output_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        output_vector2 = np.dot(self.who, \n",
    "                                output_hidden)\n",
    "        output_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_network\n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_network * \\\n",
    "              (1.0 - output_network)     \n",
    "        tmp = self.learning_rate  * np.dot(tmp, \n",
    "                                           output_hidden.T)\n",
    "        self.who += tmp\n",
    "\n",
    "\n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.who.T, \n",
    "                               output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_hidden * (1.0 - output_hidden)\n",
    "        self.wih += self.learning_rate * np.dot(tmp, input_vector.T)\n",
    "        \n",
    "\n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        intermediate_weights = []\n",
    "        for epoch in range(epochs):  \n",
    "            print(\"*\", end=\"\")\n",
    "            for i in range(len(data_array)):\n",
    "                self.train_single(data_array[i], \n",
    "                                  labels_one_hot_array[i])\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append((self.wih.copy(), \n",
    "                                             self.who.copy()))\n",
    "        return intermediate_weights        \n",
    "            \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        cm = {}\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            if (target, res_max) in cm:\n",
    "                cm[(target, res_max)] += 1\n",
    "            else:\n",
    "                cm[(target, res_max)] = 1\n",
    "        return cm\n",
    "        \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        \"\"\" input_vector can be tuple, list or ndarray \"\"\"\n",
    "        \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        output_vector = np.dot(self.wih, \n",
    "                               input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        output_vector = np.dot(self.who, \n",
    "                               output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "    \n",
    "        return output_vector\n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "ANN = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
    "                               no_of_out_nodes = 10, \n",
    "                               no_of_hidden_nodes = 100,\n",
    "                               learning_rate = 0.15)\n",
    "    \n",
    "    \n",
    " \n",
    "weights = ANN.train(train_imgs, \n",
    "                    train_labels_one_hot, \n",
    "                    epochs=epochs, \n",
    "                    intermediate_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.47628066e-02]\n",
      " [8.31205638e-03]\n",
      " [1.15186767e-04]\n",
      " [5.25863400e-03]\n",
      " [8.96510557e-04]\n",
      " [8.57431726e-03]\n",
      " [5.43086905e-05]\n",
      " [2.19589572e-04]\n",
      " [9.99669754e-01]\n",
      " [1.99263760e-02]]\n"
     ]
    }
   ],
   "source": [
    "cm = ANN.confusion_matrix(train_imgs, train_labels)\n",
    "        \n",
    "print(ANN.run(train_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0.0, 0), 5858), ((0.0, 2), 2), ((0.0, 3), 2), ((0.0, 4), 13), ((0.0, 5), 3), ((0.0, 6), 15), ((0.0, 8), 25), ((0.0, 9), 5), ((1.0, 0), 1), ((1.0, 1), 6674), ((1.0, 2), 19), ((1.0, 3), 7), ((1.0, 4), 7), ((1.0, 5), 7), ((1.0, 7), 8), ((1.0, 8), 15), ((1.0, 9), 4), ((2.0, 0), 45), ((2.0, 1), 15), ((2.0, 2), 5800), ((2.0, 3), 18), ((2.0, 4), 18), ((2.0, 5), 8), ((2.0, 6), 6), ((2.0, 7), 17), ((2.0, 8), 28), ((2.0, 9), 3), ((3.0, 0), 27), ((3.0, 1), 4), ((3.0, 2), 33), ((3.0, 3), 5898), ((3.0, 4), 8), ((3.0, 5), 60), ((3.0, 6), 5), ((3.0, 7), 20), ((3.0, 8), 49), ((3.0, 9), 27), ((4.0, 0), 26), ((4.0, 1), 12), ((4.0, 2), 3), ((4.0, 3), 1), ((4.0, 4), 5700), ((4.0, 6), 13), ((4.0, 7), 8), ((4.0, 8), 14), ((4.0, 9), 65), ((5.0, 0), 18), ((5.0, 1), 5), ((5.0, 2), 4), ((5.0, 3), 41), ((5.0, 4), 6), ((5.0, 5), 5263), ((5.0, 6), 23), ((5.0, 7), 1), ((5.0, 8), 32), ((5.0, 9), 28), ((6.0, 0), 84), ((6.0, 1), 8), ((6.0, 2), 2), ((6.0, 4), 20), ((6.0, 5), 23), ((6.0, 6), 5741), ((6.0, 8), 40), ((7.0, 0), 14), ((7.0, 1), 28), ((7.0, 2), 57), ((7.0, 3), 11), ((7.0, 4), 26), ((7.0, 5), 7), ((7.0, 6), 2), ((7.0, 7), 6057), ((7.0, 8), 18), ((7.0, 9), 45), ((8.0, 0), 51), ((8.0, 1), 64), ((8.0, 2), 16), ((8.0, 3), 25), ((8.0, 4), 17), ((8.0, 5), 32), ((8.0, 6), 17), ((8.0, 7), 4), ((8.0, 8), 5586), ((8.0, 9), 39), ((9.0, 0), 27), ((9.0, 1), 11), ((9.0, 2), 2), ((9.0, 3), 23), ((9.0, 4), 86), ((9.0, 5), 28), ((9.0, 6), 5), ((9.0, 7), 28), ((9.0, 8), 28), ((9.0, 9), 5711)]\n"
     ]
    }
   ],
   "source": [
    "cm = list(cm.items())\n",
    "print(sorted(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "accuracy train:  0.951\n",
      "accuracy: test 0.9484\n",
      "epoch:  1\n",
      "accuracy train:  0.9569\n",
      "accuracy: test 0.9486\n",
      "epoch:  2\n",
      "accuracy train:  0.96405\n",
      "accuracy: test 0.9558\n",
      "epoch:  3\n",
      "accuracy train:  0.96435\n",
      "accuracy: test 0.9534\n",
      "epoch:  4\n",
      "accuracy train:  0.9650333333333333\n",
      "accuracy: test 0.9562\n",
      "epoch:  5\n",
      "accuracy train:  0.9690166666666666\n",
      "accuracy: test 0.9566\n",
      "epoch:  6\n",
      "accuracy train:  0.9711333333333333\n",
      "accuracy: test 0.9598\n",
      "epoch:  7\n",
      "accuracy train:  0.9721\n",
      "accuracy: test 0.9562\n",
      "epoch:  8\n",
      "accuracy train:  0.97295\n",
      "accuracy: test 0.9601\n",
      "epoch:  9\n",
      "accuracy train:  0.9714666666666667\n",
      "accuracy: test 0.9593\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):  \n",
    "    print(\"epoch: \", i)\n",
    "    ANN.wih = weights[i][0]\n",
    "    ANN.who = weights[i][1]\n",
    "   \n",
    "    corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\n",
    "    print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
    "    corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\n",
    "    print(\"accuracy: test\", corrects / ( corrects + wrongs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "With Bias Nodes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "activation_function = sigmoid\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd, \n",
    "                     (upp - mean) / sd, \n",
    "                     loc=mean, \n",
    "                     scale=sd)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "        \n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "\n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes      \n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes     \n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "    \n",
    "        \n",
    "    \n",
    "    def create_weight_matrices(self):\n",
    "        \"\"\" \n",
    "        A method to initialize the weight \n",
    "        matrices of the neural network with \n",
    "        optional bias nodes\n",
    "        \"\"\"\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        \n",
    "        rad = 1 / np.sqrt(self.no_of_in_nodes + bias_node)\n",
    "        X = truncated_normal(mean=0, \n",
    "                             sd=1, \n",
    "                             low=-rad, \n",
    "                             upp=rad)\n",
    "        self.wih = X.rvs((self.no_of_hidden_nodes, \n",
    "                          self.no_of_in_nodes + bias_node))\n",
    "\n",
    "        rad = 1 / np.sqrt(self.no_of_hidden_nodes + bias_node)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        self.who = X.rvs((self.no_of_out_nodes, \n",
    "                          self.no_of_hidden_nodes + bias_node))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self, input_vector, target_vector):\n",
    "        \"\"\" \n",
    "        input_vector and target_vector can \n",
    "        be tuple, list or ndarray\n",
    "        \"\"\"\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate((input_vector, \n",
    "                                           [self.bias]) )\n",
    "                                    \n",
    "            \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "\n",
    "        \n",
    "        output_vector1 = np.dot(self.wih, \n",
    "                                input_vector)\n",
    "        output_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_hidden = np.concatenate((output_hidden, \n",
    "                                            [[self.bias]]) )\n",
    "        \n",
    "        \n",
    "        output_vector2 = np.dot(self.who, \n",
    "                                output_hidden)\n",
    "        output_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_network\n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_network * (1.0 - output_network)     \n",
    "        tmp = self.learning_rate  * np.dot(tmp, output_hidden.T)\n",
    "        self.who += tmp\n",
    "\n",
    "\n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.who.T, \n",
    "                               output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_hidden * (1.0 - output_hidden)\n",
    "        if self.bias:\n",
    "            x = np.dot(tmp, input_vector.T)[:-1,:]     \n",
    "        else:\n",
    "            x = np.dot(tmp, input_vector.T)\n",
    "        self.wih += self.learning_rate * x\n",
    "        \n",
    "       \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        \"\"\"\n",
    "        input_vector can be tuple, list or ndarray\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate((input_vector, [1]) )\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        output_vector = np.dot(self.wih, \n",
    "                               input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector = np.concatenate( (output_vector, \n",
    "                                             [[1]]) )\n",
    "            \n",
    "\n",
    "        output_vector = np.dot(self.who, \n",
    "                               output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        return output_vector\n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.] 7 0.9934951948599736\n",
      "[2.] 2 0.9256015277907452\n",
      "[1.] 1 0.9900151075820861\n",
      "[0.] 0 0.963851284804999\n",
      "[4.] 4 0.9480539370968422\n",
      "[1.] 1 0.988374562303409\n",
      "[4.] 4 0.9739467899987087\n",
      "[9.] 9 0.9829355345372894\n",
      "[5.] 6 0.4581403414865298\n",
      "[9.] 9 0.9895002858470044\n",
      "[0.] 0 0.9880533630474012\n",
      "[6.] 6 0.8582770923463678\n",
      "[9.] 9 0.9952806040933867\n",
      "[0.] 0 0.9899474117896598\n",
      "[1.] 1 0.9881921505001295\n",
      "[5.] 5 0.9305312693115744\n",
      "[9.] 9 0.9883519946542543\n",
      "[7.] 7 0.9797936882643336\n",
      "[3.] 3 0.8409929557455251\n",
      "[4.] 4 0.9907060648139673\n"
     ]
    }
   ],
   "source": [
    "ANN = NeuralNetwork(no_of_in_nodes=image_pixels, \n",
    "                    no_of_out_nodes=10, \n",
    "                    no_of_hidden_nodes=200,\n",
    "                    learning_rate=0.1,\n",
    "                    bias=None)\n",
    "    \n",
    "    \n",
    "for i in range(len(train_imgs)):\n",
    "    ANN.train(train_imgs[i], train_labels_one_hot[i])\n",
    "for i in range(20):\n",
    "    res = ANN.run(test_imgs[i])\n",
    "    print(test_labels[i], np.argmax(res), np.max(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train:  0.95365\n",
      "accuracy: test 0.9523\n"
     ]
    }
   ],
   "source": [
    "corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\n",
    "print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
    "corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\n",
    "print(\"accuracy: test\", corrects / ( corrects + wrongs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Version with Bias and Epochs:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "activation_function = sigmoid\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd,\n",
    "                     (upp - mean) / sd,\n",
    "                     loc=mean,\n",
    "                     scale=sd)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    " \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "\n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes\n",
    "        \n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "            \n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "    \n",
    "        \n",
    "    \n",
    "    def create_weight_matrices(self):\n",
    "        \"\"\" \n",
    "        A method to initialize the weight matrices \n",
    "        of the neural network with optional \n",
    "        bias nodes\"\"\"\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        \n",
    "        rad = 1 / np.sqrt(self.no_of_in_nodes + bias_node)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        self.wih = X.rvs((self.no_of_hidden_nodes, \n",
    "                          self.no_of_in_nodes + bias_node))\n",
    "\n",
    "        rad = 1 / np.sqrt(self.no_of_hidden_nodes + bias_node)\n",
    "        X = truncated_normal(mean=0, \n",
    "                             sd=1, \n",
    "                             low=-rad, \n",
    "                             upp=rad)\n",
    "        self.who = X.rvs((self.no_of_out_nodes, \n",
    "                          self.no_of_hidden_nodes + bias_node))\n",
    "        \n",
    " \n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        \"\"\"\n",
    "        input_vector and target_vector can be tuple, \n",
    "        list or ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        bias_node = 1 if self.bias else 0\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector, \n",
    "                                            [self.bias]) )\n",
    "        \n",
    "        output_vectors = []\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "\n",
    "        \n",
    "        output_vector1 = np.dot(self.wih, \n",
    "                                input_vector)\n",
    "        output_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_hidden = np.concatenate((output_hidden, \n",
    "                                            [[self.bias]]) )\n",
    "\n",
    "        \n",
    "        output_vector2 = np.dot(self.who, \n",
    "                                output_hidden)\n",
    "        output_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_network\n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_network * (1.0 - output_network)          \n",
    "        tmp = self.learning_rate  * np.dot(tmp, \n",
    "                                           output_hidden.T) \n",
    "        self.who += tmp\n",
    "\n",
    "        \n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.who.T, \n",
    "                               output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_hidden * (1.0 - output_hidden)\n",
    "        if self.bias:\n",
    "            x = np.dot(tmp, input_vector.T)[:-1,:] \n",
    "        else:\n",
    "            x = np.dot(tmp, input_vector.T)\n",
    "        self.wih += self.learning_rate * x\n",
    "        \n",
    "\n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        intermediate_weights = []\n",
    "        for epoch in range(epochs):  \n",
    "            for i in range(len(data_array)):\n",
    "                self.train_single(data_array[i], \n",
    "                                  labels_one_hot_array[i])\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append((self.wih.copy(), \n",
    "                                             self.who.copy()))\n",
    "        return intermediate_weights      \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        \n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector, \n",
    "                                            [self.bias]) )\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        output_vector = np.dot(self.wih, \n",
    "                               input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector = np.concatenate( (output_vector, \n",
    "                                             [[self.bias]]) )\n",
    "            \n",
    "\n",
    "        output_vector = np.dot(self.who, \n",
    "                               output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "    \n",
    "        return output_vector\n",
    "    \n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "accuracy train:  0.9454166666666667\n",
      "accuracy test:  0.944\n",
      "epoch:  1\n",
      "accuracy train:  0.9612166666666667\n",
      "accuracy test:  0.9565\n",
      "epoch:  2\n",
      "accuracy train:  0.9638666666666666\n",
      "accuracy test:  0.9574\n",
      "epoch:  3\n",
      "accuracy train:  0.9696666666666667\n",
      "accuracy test:  0.9621\n",
      "epoch:  4\n",
      "accuracy train:  0.9721833333333333\n",
      "accuracy test:  0.9636\n",
      "epoch:  5\n",
      "accuracy train:  0.9734333333333334\n",
      "accuracy test:  0.9636\n",
      "epoch:  6\n",
      "accuracy train:  0.9742\n",
      "accuracy test:  0.9616\n",
      "epoch:  7\n",
      "accuracy train:  0.9731666666666666\n",
      "accuracy test:  0.9623\n",
      "epoch:  8\n",
      "accuracy train:  0.9765\n",
      "accuracy test:  0.9627\n",
      "epoch:  9\n",
      "accuracy train:  0.9760166666666666\n",
      "accuracy test:  0.9647\n",
      "epoch:  10\n",
      "accuracy train:  0.9733333333333334\n",
      "accuracy test:  0.9606\n",
      "epoch:  11\n",
      "accuracy train:  0.9752666666666666\n",
      "accuracy test:  0.9607\n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "\n",
    "network = NeuralNetwork(no_of_in_nodes=image_pixels, \n",
    "                        no_of_out_nodes=10, \n",
    "                        no_of_hidden_nodes=100,\n",
    "                        learning_rate=0.1,\n",
    "                        bias=None)\n",
    "\n",
    "weights = network.train(train_imgs, \n",
    "                        train_labels_one_hot, \n",
    "                        epochs=epochs, \n",
    "                        intermediate_results=True) \n",
    "for epoch in range(epochs):  \n",
    "    print(\"epoch: \", epoch)\n",
    "    network.wih = weights[epoch][0]\n",
    "    network.who = weights[epoch][1]\n",
    "    corrects, wrongs = network.evaluate(train_imgs, \n",
    "                                        train_labels)\n",
    "    print(\"accuracy train: \", corrects / ( corrects + wrongs))                   \n",
    "    corrects, wrongs = network.evaluate(test_imgs, \n",
    "                                        test_labels)\n",
    "    print(\"accuracy test: \", corrects / ( corrects + wrongs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "\n",
    "\n",
    "with open(\"nist_tests.csv\", \"w\") as fh_out:  \n",
    "    for hidden_nodes in [20, 50, 100, 120, 150]:\n",
    "        for learning_rate in [0.01, 0.05, 0.1, 0.2]:\n",
    "            for bias in [None, 0.5]:\n",
    "                network = NeuralNetwork(no_of_in_nodes=image_pixels, \n",
    "                                       no_of_out_nodes=10, \n",
    "                                       no_of_hidden_nodes=hidden_nodes,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       bias=bias)\n",
    "                weights = network.train(train_imgs, \n",
    "                                       train_labels_one_hot, \n",
    "                                       epochs=epochs, \n",
    "                                       intermediate_results=True) \n",
    "                for epoch in range(epochs):  \n",
    "                    print(\"*\", end=\"\")\n",
    "                    network.wih = weights[epoch][0]\n",
    "                    network.who = weights[epoch][1]\n",
    "                    train_corrects, train_wrongs = network.evaluate(train_imgs, \n",
    "                                                                    train_labels)\n",
    "                    \n",
    "                    test_corrects, test_wrongs = network.evaluate(test_imgs, \n",
    "                                                                  test_labels)\n",
    "                    outstr = str(hidden_nodes) + \" \" + str(learning_rate) + \" \" + str(bias) \n",
    "                    outstr += \" \" + str(epoch) + \" \"\n",
    "                    outstr += str(train_corrects / (train_corrects + train_wrongs)) + \" \"\n",
    "                    outstr += str(train_wrongs / (train_corrects + train_wrongs)) + \" \"\n",
    "                    outstr += str(test_corrects / (test_corrects + test_wrongs)) + \" \"\n",
    "                    outstr += str(test_wrongs / (test_corrects + test_wrongs)) \n",
    "                    \n",
    "                    fh_out.write(outstr + \"\\n\" )\n",
    "                    fh_out.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Networks with multiple hidden layers\n",
    "---\n",
    "We will write a new neural network class, in which we can define an arbitrary number of hidden layers. The code is also improved, because the weight matrices are now build inside of a loop instead redundant code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd, \n",
    "                     (upp - mean) / sd, \n",
    "                     loc=mean, \n",
    "                     scale=sd)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "        \n",
    "    \n",
    "    def __init__(self, \n",
    "                 network_structure, # ie. [input_nodes, hidden1_nodes, ... , hidden_n_nodes, output_nodes]\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "\n",
    "        self.structure = network_structure\n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "    \n",
    "    \n",
    "    def create_weight_matrices(self):\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        self.weights_matrices = []\n",
    "        \n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        while layer_index < no_of_layers:\n",
    "            nodes_in = self.structure[layer_index-1]\n",
    "            nodes_out = self.structure[layer_index]\n",
    "            n = (nodes_in + bias_node) * nodes_out\n",
    "            rad = 1 / np.sqrt(nodes_in)\n",
    "            X = truncated_normal(mean=2, \n",
    "                                 sd=1, \n",
    "                                 low=-rad, \n",
    "                                 upp=rad)\n",
    "            wm = X.rvs(n).reshape((nodes_out, nodes_in + bias_node))\n",
    "            self.weights_matrices.append(wm)\n",
    "            layer_index += 1\n",
    "\n",
    "        \n",
    "        \n",
    "    def train(self, input_vector, target_vector):\n",
    "        \"\"\"\n",
    "        input_vector and target_vector can be tuple, \n",
    "        list or ndarray\n",
    "        \"\"\"                              \n",
    "\n",
    "        no_of_layers = len(self.structure)\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        layer_index = 0\n",
    "        # The output/input vectors of the various layers:\n",
    "        res_vectors = [input_vector]\n",
    "        while layer_index < no_of_layers - 1:\n",
    "            in_vector = res_vectors[-1]\n",
    "            if self.bias:\n",
    "                # adding bias node to the end of the 'input'_vector\n",
    "                in_vector = np.concatenate( (in_vector, \n",
    "                                             [[self.bias]]) )\n",
    "                res_vectors[-1] = in_vector\n",
    "            x = np.dot(self.weights_matrices[layer_index], \n",
    "                       in_vector)\n",
    "            out_vector = activation_function(x)\n",
    "            # the output of one layer is the input of the next one:\n",
    "            res_vectors.append(out_vector)    \n",
    "            layer_index += 1\n",
    "        \n",
    "        layer_index = no_of_layers - 1\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "         # The input vectors to the various layers\n",
    "        output_errors = target_vector - out_vector  \n",
    "        while layer_index > 0:\n",
    "            out_vector = res_vectors[layer_index]\n",
    "            in_vector = res_vectors[layer_index-1]\n",
    "\n",
    "            if self.bias and not layer_index==(no_of_layers-1):\n",
    "                out_vector = out_vector[:-1,:].copy()\n",
    "\n",
    "            tmp = output_errors * out_vector * (1.0 - out_vector)     \n",
    "            tmp = np.dot(tmp, in_vector.T)\n",
    "            \n",
    "            #if self.bias:\n",
    "            #    tmp = tmp[:-1,:] \n",
    "                \n",
    "            self.weights_matrices[layer_index-1] += self.learning_rate * tmp\n",
    "            \n",
    "            output_errors = np.dot(self.weights_matrices[layer_index-1].T, \n",
    "                                   output_errors)\n",
    "            if self.bias:\n",
    "                output_errors = output_errors[:-1,:]\n",
    "            layer_index -= 1\n",
    "            \n",
    "            \n",
    "               \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "\n",
    "        no_of_layers = len(self.structure)\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector, \n",
    "                                            [self.bias]) )\n",
    "        in_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        layer_index = 1\n",
    "        # The input vectors to the various layers\n",
    "        while layer_index < no_of_layers:\n",
    "            x = np.dot(self.weights_matrices[layer_index-1], \n",
    "                       in_vector)\n",
    "            out_vector = activation_function(x)\n",
    "            \n",
    "            # input vector for next layer\n",
    "            in_vector = out_vector\n",
    "            if self.bias:\n",
    "                in_vector = np.concatenate( (in_vector, \n",
    "                                             [[self.bias]]) )            \n",
    "            \n",
    "            layer_index += 1\n",
    "  \n",
    "    \n",
    "        return out_vector\n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN = NeuralNetwork(network_structure=[image_pixels, 50, 50, 10],\n",
    "                               learning_rate=0.1,\n",
    "                               bias=None)\n",
    "    \n",
    "    \n",
    "for i in range(len(train_imgs)):\n",
    "    ANN.train(train_imgs[i], train_labels_one_hot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\n",
    "print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
    "corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\n",
    "print(\"accuracy: test\", corrects / ( corrects + wrongs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Networks with multiple hidden layers and Epochs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd,\n",
    "                     (upp - mean) / sd, \n",
    "                     loc=mean, \n",
    "                     scale=sd)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "        \n",
    "    \n",
    "    def __init__(self, \n",
    "                 network_structure, # ie. [input_nodes, hidden1_nodes, ... , hidden_n_nodes, output_nodes]\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "\n",
    "        self.structure = network_structure\n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "\n",
    "    \n",
    "    \n",
    "    def create_weight_matrices(self):\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        self.weights_matrices = []    \n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        while layer_index < no_of_layers:\n",
    "            nodes_in = self.structure[layer_index-1]\n",
    "            nodes_out = self.structure[layer_index]\n",
    "            n = (nodes_in + bias_node) * nodes_out\n",
    "            rad = 1 / np.sqrt(nodes_in)\n",
    "            X = truncated_normal(mean=2, sd=1, low=-rad, upp=rad)\n",
    "            wm = X.rvs(n).reshape((nodes_out, nodes_in + bias_node))\n",
    "            self.weights_matrices.append(wm)\n",
    "            layer_index += 1\n",
    "\n",
    "        \n",
    "        \n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        # input_vector and target_vector can be tuple, list or ndarray\n",
    "                                       \n",
    "        no_of_layers = len(self.structure)        \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        layer_index = 0\n",
    "        # The output/input vectors of the various layers:\n",
    "        res_vectors = [input_vector]          \n",
    "        while layer_index < no_of_layers - 1:\n",
    "            in_vector = res_vectors[-1]\n",
    "            if self.bias:\n",
    "                # adding bias node to the end of the 'input'_vector\n",
    "                in_vector = np.concatenate( (in_vector, \n",
    "                                             [[self.bias]]) )\n",
    "                res_vectors[-1] = in_vector\n",
    "            x = np.dot(self.weights_matrices[layer_index], in_vector)\n",
    "            out_vector = activation_function(x)\n",
    "            res_vectors.append(out_vector)   \n",
    "            layer_index += 1\n",
    "        \n",
    "        layer_index = no_of_layers - 1\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "         # The input vectors to the various layers\n",
    "        output_errors = target_vector - out_vector  \n",
    "        while layer_index > 0:\n",
    "            out_vector = res_vectors[layer_index]\n",
    "            in_vector = res_vectors[layer_index-1]\n",
    "\n",
    "            if self.bias and not layer_index==(no_of_layers-1):\n",
    "                out_vector = out_vector[:-1,:].copy()\n",
    "\n",
    "            tmp = output_errors * out_vector * (1.0 - out_vector)     \n",
    "            tmp = np.dot(tmp, in_vector.T)\n",
    "            \n",
    "            #if self.bias:\n",
    "            #    tmp = tmp[:-1,:] \n",
    "                \n",
    "            self.weights_matrices[layer_index-1] += self.learning_rate * tmp\n",
    "            \n",
    "            output_errors = np.dot(self.weights_matrices[layer_index-1].T, \n",
    "                                   output_errors)\n",
    "            if self.bias:\n",
    "                output_errors = output_errors[:-1,:]\n",
    "            layer_index -= 1\n",
    "            \n",
    "\n",
    "       \n",
    "\n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        intermediate_weights = []\n",
    "        for epoch in range(epochs):  \n",
    "            for i in range(len(data_array)):\n",
    "                self.train_single(data_array[i], labels_one_hot_array[i])\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append((self.wih.copy(), \n",
    "                                             self.who.copy()))\n",
    "        return intermediate_weights      \n",
    "        \n",
    "\n",
    "               \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "\n",
    "        no_of_layers = len(self.structure)\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
    "        in_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        layer_index = 1\n",
    "        # The input vectors to the various layers\n",
    "        while layer_index < no_of_layers:\n",
    "            x = np.dot(self.weights_matrices[layer_index-1], \n",
    "                       in_vector)\n",
    "            out_vector = activation_function(x)\n",
    "            \n",
    "            # input vector for next layer\n",
    "            in_vector = out_vector\n",
    "            if self.bias:\n",
    "                in_vector = np.concatenate( (in_vector, \n",
    "                                             [[self.bias]]) )            \n",
    "            \n",
    "            layer_index += 1\n",
    "  \n",
    "    \n",
    "        return out_vector\n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "ANN = NeuralNetwork(network_structure=[image_pixels, 80, 80, 10],\n",
    "                               learning_rate=0.01,\n",
    "                               bias=None)\n",
    "    \n",
    "    \n",
    "ANN.train(train_imgs, train_labels_one_hot, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\n",
    "print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
    "corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\n",
    "print(\"accuracy: test\", corrects / ( corrects + wrongs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
